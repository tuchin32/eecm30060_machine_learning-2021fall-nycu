{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"b445ccfa557170e9a1397e58540c0ba15a3370c0d87db55f340afe85843e37a4"},"kernelspec":{"display_name":"Python 3.8.10 64-bit ('env38': virtualenv)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"hw1_0710755.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"L5Cu1iR1vdzS","executionInfo":{"status":"ok","timestamp":1635510225489,"user_tz":-480,"elapsed":257,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","data_x_df = pd.read_csv('data_X.csv')\n","data_t_df = pd.read_csv('data_T.csv')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"yY0to1_RvdzW","executionInfo":{"status":"ok","timestamp":1635510228668,"user_tz":-480,"elapsed":262,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}}},"source":["input_size = data_x_df.shape[0]\n","try:\n","    if data_x_df.shape[0] == data_t_df.shape[0]:\n","        pass\n","except:\n","    print('Numbers of data size mismatch!!')\n","\n","# Turn dataset into numpy form and random shuffle\n","data_df = pd.merge(data_x_df, data_t_df, left_index=True, right_index=True)\n","data = np.array(data_df)\n","np.random.seed(1)\n","np.random.shuffle(data)\n","\n","# Divide the dataset into training and validation\n","train_x = data[:int(0.9 * input_size), 0:8]\n","train_t = data[:int(0.9 * input_size), 8]\n","\n","valid_x = data[int(0.9 * input_size):, 0:8]\n","valid_t = data[int(0.9 * input_size):, 8]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqqmqmK4wSGW","executionInfo":{"status":"ok","timestamp":1635510233829,"user_tz":-480,"elapsed":282,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}}},"source":["def root_mean_square_error(x, w, t):\n","    y_xw = np.dot(x, w)\n","    error = 0.5 * np.mean((y_xw - t) ** 2)\n","    rms_error = np.sqrt(2 * np.array(error))\n","    return rms_error\n","\n","# w_ls = (x_T * x)^(-1) * x_T * y\n","def least_square(x, t):\n","    tmp_inv = np.linalg.pinv(np.dot(x.T, x))\n","    w_ls = np.dot(np.dot(tmp_inv, x.T), t)\n","    return w_ls\n","\n","# w_rls = (x_T * x + lambda * I)^(-1) * x_T * y\n","def regularize_least_square(x, t, lambda_rls=1):\n","    tmp = np.dot(x.T, x)\n","    tmp_inv = np.linalg.pinv(tmp + lambda_rls * np.eye(tmp.shape[0]))\n","    w_rls = np.dot(np.dot(tmp_inv, x.T), t)\n","    return w_rls\n","\n","def basis_function(x, order=1, features=8):\n","    phi_x = np.full((x.shape[0], 1), 1)\n","    \n","    for ord in range(1, order + 1):\n","        #for comb in list(repeat_combination(range(features), ord)):\n","        for comb in list(product_permute(range(features), repeat=ord)):\n","            product = np.prod(x[:, comb], axis=1)\n","            new_col = np.expand_dims(product, axis=1)\n","            phi_x = np.concatenate((phi_x, new_col), axis=1)\n","    return phi_x\n","\n","def poly_basis_function(x, order=1, features=8):\n","    phi_x = np.full((x.shape[0], 1), 1)\n","    \n","    for ord in range(1, order + 1):\n","        for deg in range(features):\n","            product = np.prod(x[:, [deg] * ord], axis=1)\n","            new_col = np.expand_dims(product, axis=1)\n","            phi_x = np.concatenate((phi_x, new_col), axis=1)\n","    return phi_x\n","\n","def repeat_combination(iterable, r):\n","    pool = tuple(iterable)\n","    n = len(pool)\n","    if not n and r:\n","        return\n","    indices = [0] * r\n","    yield tuple(pool[i] for i in indices)\n","    while True:\n","        for i in reversed(range(r)):\n","            if indices[i] != n - 1:\n","                break\n","        else:\n","            return\n","        indices[i:] = [indices[i] + 1] * (r - i)\n","        yield tuple(pool[i] for i in indices)\n","\n","def product_permute(*args, repeat=1):\n","    pools = [tuple(pool) for pool in args] * repeat\n","    result = [[]]\n","    for pool in pools:\n","        result = [x+[y] for x in result for y in pool]\n","    for prod in result:\n","        yield tuple(prod)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fg01gd5lprZc"},"source":["## Problem 2-1 Feature Selection\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lB8joN4BpTzk"},"source":["**Part a**\n","> Apply polynomials of order M = 1 and M = 2 over the dimension D = 8 \n","input data.\n","> Also, evaluate the corresponding RMS error on the training set and valid set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNC_uBVPSKdw","executionInfo":{"status":"ok","timestamp":1635510253954,"user_tz":-480,"elapsed":694,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}},"outputId":"a18b26ee-b9a3-4745-d429-a9a7aed78b9a"},"source":["train_rms_error = []\n","valid_rms_error = []\n","\n","# Apply polynomials of order M = 1 and M = 2\n","for m in range(1, 3):\n","    train_phi_x = basis_function(train_x, m, 8)\n","    w = least_square(train_phi_x, train_t)\n","    rms_error = root_mean_square_error(train_phi_x, w, train_t)\n","    train_rms_error.append(rms_error)\n","    \n","    valid_phi_x = basis_function(valid_x, m, 8)\n","    rms_error = root_mean_square_error(valid_phi_x, w, valid_t)\n","    valid_rms_error.append(rms_error)\n","\n","    if m == 1:\n","        print('Weights @ M = 1')\n","        print(w)\n","    \n","print('\\nTraining Stage:')\n","print('M = 1, RMS Error =', train_rms_error[0], '\\nM = 2, RMS Error =', train_rms_error[1])\n","print('\\nValidation Stage:')\n","print('M = 1, RMS Error =', valid_rms_error[0], '\\nM = 2, RMS Error =', valid_rms_error[1])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights @ M = 1\n","[-3.56141127e+06 -4.24450562e+04 -4.22801376e+04  1.19697293e+03\n"," -8.63932391e+00  1.17358660e+02 -3.82454441e+01  4.63726750e+01\n","  4.04914293e+04]\n","\n","Training Stage:\n","M = 1, RMS Error = 69420.81601487994 \n","M = 2, RMS Error = 66666.41441382407\n","\n","Validation Stage:\n","M = 1, RMS Error = 70793.96207221576 \n","M = 2, RMS Error = 68980.40899604809\n"]}]},{"cell_type":"markdown","metadata":{"id":"cKTIXFytrit1"},"source":["**Part b**\n","> Analysis the weights of polynomial model M = 1 and select the most\n","contributive feature."]},{"cell_type":"markdown","metadata":{"id":"30jIl6jdBFtw"},"source":["In polynomial model M = 1, there are 8 weights totally. Besides, the last weight has the largest value."]},{"cell_type":"markdown","metadata":{"id":"_M-bZEokuYb3"},"source":["There are two methods to find the most contributive feature.\n","\n","1.   Remove one of the features and compute RMS errors. Find the largest error, and the excluded feature is most contributive one. That is, without the feature, the prediction will be unreliable. \n","\n","2.   Use one of the features and compute RMS errors. Find the smallest error, and the feature is most contributive one. This method is feasible as the feature is more dominant than any other one.\n","\n","I will use the second method firstly.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljcpq8V4mZKo","executionInfo":{"status":"ok","timestamp":1635510263393,"user_tz":-480,"elapsed":405,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}},"outputId":"2bad29fd-954d-44b6-8c28-89907f4d4659"},"source":["input_features = ['longitude', 'latitude', 'hous\u0002ing_median_age', 'total_rooms', \n","                  'total_bedrooms', 'population', 'households', 'median_income']\n","\n","for i in range(8):\n","    train_phi_x = basis_function(train_x[:, [i]], order=1, features=1)\n","    w = least_square(train_phi_x, train_t)\n","    rms_error = root_mean_square_error(train_phi_x, w, train_t)\n","\n","    print(\"With Feature: %-18s, RMS Error = %f\" %(input_features[i], rms_error))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["With Feature: longitude         , RMS Error = 115678.517473\n","With Feature: latitude          , RMS Error = 114606.037072\n","With Feature: hous\u0002ing_median_age, RMS Error = 115111.297709\n","With Feature: total_rooms       , RMS Error = 114777.389042\n","With Feature: total_bedrooms    , RMS Error = 115672.773325\n","With Feature: population        , RMS Error = 115757.934509\n","With Feature: households        , RMS Error = 115574.487669\n","With Feature: median_income     , RMS Error = 83681.436014\n"]}]},{"cell_type":"markdown","metadata":{"id":"nWobqI6ttZFs"},"source":["The last feature corresponds to the smallest RMS error. Apparently, the most contributive feature is `median_income`.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"flMT_Rjlw8vp"},"source":["## Problem 2-2 Maximum Likelihood Approach"]},{"cell_type":"markdown","metadata":{"id":"p4DQ-mz4fXs2"},"source":["**Part a**\n","> Choose one of the following basis functions, polynomial, Gaussian, Sigmoid, or hybrid, to further improve your regression model."]},{"cell_type":"markdown","metadata":{"id":"mRNtnkjSWmzs"},"source":["I choose modified `polynomial` basis function for the following reasons.\n","\n","\n","1.   Polynomial basis function has fexibility to choose the degree of order. Hence, the number of parameters, i.e., the shape of the design matrix, can be adjusted easily.\n","2.   Some hyperparameters in Gaussian or sigmoid basis function are not easily determined in this case.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oZhLam72zCht"},"source":["**Part b**\n","> Analyze the result of the basis function introduced to linear regression model."]},{"cell_type":"code","metadata":{"id":"28bgRJ_EzyR4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635510998362,"user_tz":-480,"elapsed":711323,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}},"outputId":"399ac889-c993-43ba-b487-cd825b52f350"},"source":["train_rms_error = []\n","valid_rms_error = []\n","order_max = 4\n","\n","for m in range(1, order_max + 1):\n","    train_phi_x = basis_function(train_x, m, 8)\n","    # print(np.shape(train_x))\n","    # print(np.shape(train_phi_x))\n","    # print('')\n","    w = least_square(train_phi_x, train_t)\n","    rms_error = root_mean_square_error(train_phi_x, w, train_t)\n","    train_rms_error.append(rms_error)\n","    \n","    valid_phi_x = basis_function(valid_x, m, 8)\n","    rms_error = root_mean_square_error(valid_phi_x, w, valid_t)\n","    valid_rms_error.append(rms_error)\n","\n","print('Training Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, train_rms_error[i]))\n","print('\\nValidation Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, valid_rms_error[i]))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Stage:\n","M = 1, RMS Error = 69420.816015\n","M = 2, RMS Error = 66666.414414\n","M = 3, RMS Error = 72415.218741\n","M = 4, RMS Error = 99211.054617\n","\n","Validation Stage:\n","M = 1, RMS Error = 70793.962072\n","M = 2, RMS Error = 68980.408996\n","M = 3, RMS Error = 78657.948600\n","M = 4, RMS Error = 149609.811942\n"]}]},{"cell_type":"markdown","metadata":{"id":"WvOxbmzwb10a"},"source":["**Part c**\n","> Apply N-fold cross-validation in the training stage to select at least one hyper\u0002parameter (order, parameter number, . . .) for model and do some discussion (un\u0002derfitting, overfitting)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_VZz25Ig5yw","executionInfo":{"status":"ok","timestamp":1635522063494,"user_tz":-480,"elapsed":1101029,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}},"outputId":"e2db4336-ce1a-4f3d-9404-415961e6a89b"},"source":["train_rms_error = []\n","valid_rms_error = []\n","N = 100\n","order_max = 3\n","\n","for m in range(1, order_max + 1):\n","    for n in range(100):\n","        train_x = np.concatenate((data[:int(n * input_size / N), 0:8], data[int((n + 1) * input_size / N):, 0:8]))\n","        train_t = np.concatenate((data[:int(n * input_size / N), 8], data[int((n + 1) * input_size / N):, 8]))\n","\n","        valid_x = data[int(n * input_size / N):int((n + 1) * input_size / N), 0:8]\n","        valid_t = data[int(n * input_size / N):int((n + 1) * input_size / N), 8]\n","\n","        train_phi_x = basis_function(train_x, order=m, features=8)\n","        w = least_square(train_phi_x, train_t)\n","\n","        if n == 0:\n","            w_av = w\n","        else:\n","            w_av += w\n","\n","    w_av /= 10.0\n","    train_rms_error.append(root_mean_square_error(train_phi_x, w_av, train_t))\n","    valid_phi_x = basis_function(valid_x, order=m, features=8)\n","    valid_rms_error.append(root_mean_square_error(valid_phi_x, w_av, valid_t))\n","\n","print('Training Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, train_rms_error[i]))\n","print('\\nValidation Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, valid_rms_error[i]))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Stage:\n","M = 1, RMS Error = 2039778.002821\n","M = 2, RMS Error = 2047005.787079\n","M = 3, RMS Error = 2031744.999810\n","\n","Validation Stage:\n","M = 1, RMS Error = 1985267.391228\n","M = 2, RMS Error = 1979472.020457\n","M = 3, RMS Error = 1968568.074199\n"]}]},{"cell_type":"markdown","metadata":{"id":"7e3Y28jlvnsu"},"source":["##Problem 2-3 Maximum a posteriori approach"]},{"cell_type":"markdown","metadata":{"id":"fCecvTV1vuvB"},"source":["**Part b**\n","> Use maximum a posteriori approach method to retest the model designed in Problem 2-2."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3TvCztwueHx","executionInfo":{"status":"ok","timestamp":1635520202911,"user_tz":-480,"elapsed":103162,"user":{"displayName":"江讀晉","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh33WPO5bSDjyL_XbuxyoGHfSiVgs1bRU3Fu7iF=s64","userId":"06285701188866046906"}},"outputId":"1c364407-edec-421f-9600-3e02dec7d4d0"},"source":["train_rms_error = []\n","valid_rms_error = []\n","N = 10\n","order_max = 3\n","\n","for m in range(1, order_max + 1):\n","    for n in range(10):\n","        train_x = np.concatenate((data[:int(n * input_size / N), 0:8], data[int((n + 1) * input_size / N):, 0:8]))\n","        train_t = np.concatenate((data[:int(n * input_size / N), 8], data[int((n + 1) * input_size / N):, 8]))\n","\n","        valid_x = data[int(n * input_size / N):int((n + 1) * input_size / N), 0:8]\n","        valid_t = data[int(n * input_size / N):int((n + 1) * input_size / N), 8]\n","\n","        train_phi_x = basis_function(train_x, order=m, features=8)\n","        w = regularize_least_square(train_phi_x, train_t, lambda_rls=10)\n","\n","        if n == 0:\n","            w_av = w\n","        else:\n","            w_av += w\n","\n","    w_av /= 10.0\n","    train_rms_error.append(root_mean_square_error(train_phi_x, w_av, train_t))\n","    valid_phi_x = basis_function(valid_x, order=m, features=8)\n","    valid_rms_error.append(root_mean_square_error(valid_phi_x, w_av, valid_t))\n","\n","print('Training Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, train_rms_error[i]))\n","print('\\nValidation Stage:')\n","for i in range(order_max):\n","    print(\"M = %d, RMS Error = %f\" % (i + 1, valid_rms_error[i]))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Stage:\n","M = 1, RMS Error = 73717.319546\n","M = 2, RMS Error = 66700.599266\n","M = 3, RMS Error = 75576.002544\n","\n","Validation Stage:\n","M = 1, RMS Error = 75619.927549\n","M = 2, RMS Error = 68661.947325\n","M = 3, RMS Error = 71987.838254\n"]}]}]}